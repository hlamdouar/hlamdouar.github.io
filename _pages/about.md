---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about me/
  - /about.html
---

I am a postdoctoral researcher at the <a href="https://ibme.ox.ac.uk">IBME</a>, University of Oxford, working with Professor <a href="https://ibme.ox.ac.uk/person/alison-noble/">Alison Noble</a>. I have completed my DPhil (PhD) at the <a href="https://www.robots.ox.ac.uk/~vgg/">Visual Geometry Group (VGG)</a>, University of Oxford, advised by Professor <a href="https://www.robots.ox.ac.uk/~az/">Andrew Zisserman</a> and Professor <a href="https://weidixie.github.io">Weidi Xie</a>. My research focuses on Video Understanding via Single and Multi-Modal learning, particularly from challenging datasets as in the clinical setting. I was also a member of the <a href="https://aims.robots.ox.ac.uk">Centre for Doctoral Training in Autonomous Intelligent Machines & Systems (AIMS)</a>.

Originally from Rabat, Morocco, I completed my Engineering degree in signal and image processing at <a href="https://enseirb-matmeca.bordeaux-inp.fr/fr">ENSEIRB-MATMECA</a> in Bordeaux, France, followed by a Master's Degree in applied mathematics with a focus on machine learning and computer vision (MVA) at <a href="http://math.ens-paris-saclay.fr/version-francaise/formations/master-mva/">Ecole Normale Superieure</a>, Paris area, where I also had the chance to work on perception solutions for autonomous driving at <a href="https://www.valeo.com/en/">Valeo</a>.


<h3 id="recent-highlights">Recent Highlights</h3>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">What makes a camouflage effective? <br>Check out our paper @ICCV23: ‚ÄúThe Making and Breaking of Camouflage‚Äù Joint work w/ <a href="https://twitter.com/WeidiXie?ref_src=twsrc%5Etfw">@WeidiXie</a> &amp; Andrew Zisserman <a href="https://twitter.com/Oxford_VGG?ref_src=twsrc%5Etfw">@Oxford_VGG</a> <br><br>arXiv: <a href="https://t.co/Cm8Xwp4vsC">https://t.co/Cm8Xwp4vsC</a><br>Poster: Wednesday 4th, 10:30 AM-12:30 PM at Room &quot;Nord&quot; 061 by the amazing <a href="https://twitter.com/TengdaHan?ref_src=twsrc%5Etfw">@TengdaHan</a> <a href="https://t.co/pofCkxqbTs">pic.twitter.com/pofCkxqbTs</a></p>&mdash; Hala (@hala_lamdouar) <a href="https://twitter.com/hala_lamdouar/status/1709272401819656681?ref_src=twsrc%5Etfw">October 3, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Check out our latest work on ‚ÄúSegmenting Invisible Moving Objects‚Äù at <a href="https://twitter.com/BMVCconf?ref_src=twsrc%5Etfw">@BMVCconf</a> (w/ <a href="https://twitter.com/WeidiXie?ref_src=twsrc%5Etfw">@WeidiXie</a> and Andrew Zisserman) <br>Project page: <a href="https://t.co/ladZeSKFRa">https://t.co/ladZeSKFRa</a> <a href="https://t.co/Bz2wQvtI1G">pic.twitter.com/Bz2wQvtI1G</a></p>&mdash; Hala (@hala_lamdouar) <a href="https://twitter.com/hala_lamdouar/status/1463819330605436933?ref_src=twsrc%5Etfw">November 25, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Check out our paper at <a href="https://twitter.com/ICCV_2021?ref_src=twsrc%5Etfw">@ICCV_2021</a>!<br><br>Self-supervised Video Object Segmentation by Motion Grouping (w/ <a href="https://twitter.com/hala_lamdouar?ref_src=twsrc%5Etfw">@hala_lamdouar</a>, <a href="https://twitter.com/erika_lu_?ref_src=twsrc%5Etfw">@erika_lu_</a>, Andrew Zisserman &amp; <a href="https://twitter.com/WeidiXie?ref_src=twsrc%5Etfw">@WeidiXie</a>)<br><br>Project page (paper+video+code): <a href="https://t.co/hNNJoOFlXc">https://t.co/hNNJoOFlXc</a> <a href="https://t.co/nPntXAxZ9K">pic.twitter.com/nPntXAxZ9K</a></p>&mdash; charig yang (@chaaarig) <a href="https://twitter.com/chaaarig/status/1444583620149121024?ref_src=twsrc%5Etfw">October 3, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Glad to have had the opportunity to collaborate with this amazing research team as part of the <a href="https://twitter.com/hashtag/FDL2021?src=hash&amp;ref_src=twsrc%5Etfw">#FDL2021</a> summer program. Looking forward to sharing our results today! <a href="https://twitter.com/NASA?ref_src=twsrc%5Etfw">@NASA</a> <a href="https://twitter.com/NASAAmes?ref_src=twsrc%5Etfw">@NASAAmes</a> <a href="https://twitter.com/SETIInstitute?ref_src=twsrc%5Etfw">@SETIInstitute</a> <a href="https://twitter.com/FDL_AI?ref_src=twsrc%5Etfw">@FDL_AI</a> <a href="https://twitter.com/hashtag/FDL?src=hash&amp;ref_src=twsrc%5Etfw">#FDL</a> <a href="https://t.co/5QsHnSpHJk">https://t.co/5QsHnSpHJk</a></p>&mdash; Hala (@hala_lamdouar) <a href="https://twitter.com/hala_lamdouar/status/1426186543249637381?ref_src=twsrc%5Etfw">August 13, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Check out our latest work <a href="https://twitter.com/accv2020?ref_src=twsrc%5Etfw">@ACCV2020</a> <a href="https://twitter.com/hashtag/ACCV2020?src=hash&amp;ref_src=twsrc%5Etfw">#ACCV2020</a> with Charig Yang, <a href="https://twitter.com/WeidiXie?ref_src=twsrc%5Etfw">@WeidiXie</a> and Andrew Zisserman.<br>We introduce MoCA, a challenging dataset for detecting camouflaged animals in videosü¶é<br>Paper: <a href="https://t.co/vBuvOzGqSS">https://t.co/vBuvOzGqSS</a><br>Poster sessions: 6-8am on Monday and 1-3pm GMT on Tuesday <a href="https://t.co/U5XBOCJJ1x">pic.twitter.com/U5XBOCJJ1x</a></p>&mdash; Hala (@hala_lamdouar) <a href="https://twitter.com/hala_lamdouar/status/1333146428634488843?ref_src=twsrc%5Etfw">November 29, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>



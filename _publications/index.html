<!doctype html>
<html lang="en" class="no-js">
<head>
    <meta charset="utf-8">
    <!-- begin SEO -->
    <title>Publications - Hala Lamdouar</title>
    <meta property="og:locale" content="en-US">
    <meta property="og:site_name" content="Hala Lamdouar">
    <meta property="og:title" content="Publications">
    <link rel="canonical" href="https://hlamdouar.github.io/">
    <meta property="og:url" content="https://hlamdouar.github.io/">
    <meta property="og:description" content="Publications">
    <script type="application/ld+json"> { "@context" : "http://schema.org", "@type" : "Person", "name" : "Hala Lamdouar", "url" : "https://hlamdouar.github.io", "sameAs" : null } </script>
    <!-- end SEO -->
    <link href="https://hlamdouar.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Hala Lamdouar Feed">
    <!-- http://t.co/dKP3o1e -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script>
    document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
    </script>
    <!-- For all browsers -->
    <link rel="stylesheet" href="https://hlamdouar.github.io/assets/css/main.css">
    <meta http-equiv="cleartype" content="on">
    <!-- start custom head snippets -->
    <link rel="apple-touch-icon" sizes="180x180" href="https://hlamdouar.github.io/images/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://hlamdouar.github.io/images/favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://hlamdouar.github.io/images/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="70x70" href="https://hlamdouar.github.io/images/favicon-70x70.png">
    <link rel="icon" type="image/png" sizes="310x150" href="https://hlamdouar.github.io/images/favicon-310x150.png">
    <link rel="icon" type="image/png" sizes="144x144" href="https://hlamdouar.github.io/images/favicon-144x144.png">
    <link rel="icon" type="image/png" sizes="150x150" href="https://hlamdouar.github.io/images/favicon-150x150.png">
    <link rel="icon" type="image/png" sizes="310x310" href="https://hlamdouar.github.io/images/favicon-310x310.png">
    <link rel="manifest" href="https://hlamdouar.github.io/images/manifest.json">
    <link rel="mask-icon" href="https://hlamdouar.github.io/images/safari-pinned-tab.svg" color="#000000">
    <link rel="shortcut icon" href="/images/favicon.ico">
    <meta name="msapplication-TileColor" content="#000000">
    <meta name="msapplication-TileImage" content="https://hlamdouar.github.io/images/mstile-144x144.png">
    <meta name="msapplication-config" content="https://hlamdouar.github.io/images/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">
    <link rel="stylesheet" href="https://hlamdouar.github.io/assets/css/academicons.css"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
            equationNumbers: {
                autoNumber: "all"
            }
        }
    });
    </script>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$', '$'], ["\\(", "\\)"]],
            processEscapes: true
        }
    });
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>
    <!-- end custom head snippets -->
</head>
<body>
    <!--[if lt IE 9]><div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->
    <div class="masthead">
        <div class="masthead__inner-wrap">
            <div class="masthead__menu">
                <nav id="site-nav" class="greedy-nav">
                    <button>
                        <div class="navicon"></div>
                    </button>
                    <ul class="visible-links">
                        <li class="masthead__menu-item masthead__menu-item--lg">
                            <a href="https://hlamdouar.github.io/">Hala Lamdouar</a>
                        </li>
                        <li class="masthead__menu-item">
                            <a href="https://hlamdouar.github.io/about me/">About Me</a>
                        </li>
                        <li class="masthead__menu-item">
                            <a href="https://hlamdouar.github.io/publications/">Publications</a>
                        </li>
                        <li class="masthead__menu-item">
                            <a href="https://hlamdouar.github.io/contact/">Contact</a>
                        </li>
                    </ul>
                    <ul class="hidden-links hidden"></ul>
                </nav>
            </div>
        </div>
    </div>
    <div id="main" role="main">
        <div class="sidebar sticky">
            <div itemscope itemtype="http://schema.org/Person">
                <div class="author__avatar">
                    <img src="https://hlamdouar.github.io/images/profile.png" class="author__avatar" alt="Hala Lamdouar هالة لمدور">
                </div>
                <div class="author__content">
                    <h3 class="author__name">Hala Lamdouar هالة لمدور</h3>
                    <p class="author__bio">DPhil Candidate Computer Vision, Machine Learning</p>
                </div>
                <div class="author__urls-wrapper">
                    <button class="btn btn--inverse">Follow</button>
                    <ul class="author__urls social-icons">
                        <li>
                            <i class="fa fa-fw fa-map-marker" aria-hidden="true"></i>
                             University of Oxford
                        </li>
                        <li>
                            <a href="https://twitter.com/hala_lamdouar">
                                <i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i>
                                 Twitter
                            </a>
                        </li>
                        <li>
                            <a href="https://scholar.google.co.uk/citations?user=PWTYyHsAAAAJ&hl=en&oi=ao">
                                <i class="fas fa-fw fa-graduation-cap"></i>
                                 Google Scholar
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <header>
        <h1 class="page__title">Publications</h1>
    </header> 
    <div class="page__inner-wrap">  
        <table style="width:150%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size:14px"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle;border:0">
                <div class="one">
                    <div class="two">
                    <img src="../images/sim2real.png">
                     </div>

            </td>
            <td style="width:75%;vertical-align:middle;border:0">
							<a href="https://www.robots.ox.ac.uk/~vgg/publications/2021/Lamdouar21/lamdouar21.pdf">
                <papertitle style="font-size:16px"><b>Segmenting Invisible Moving Objects</b></papertitle>
              </a>
              <br>
              <strong>Hala Lamdouar</strong>, 
              <a style="text-decoration:none" href="https://weidixie.github.io/">Weidi Xie</a>,
              <a style="text-decoration:none" href="http://www.robots.ox.ac.uk/~az/">Andrew Zisserman</a>
              <br>
              <em>BMVC</em>, 2021 
              <br>
                   <div class="links">
                       <a onclick="if (document.getElementById(&quot;BIBLamdouar21&quot;).style.display==&quot;none&quot;) document.getElementById(&quot;BIBLamdouar21&quot;).style.display=&quot;block&quot;; else document.getElementById(&quot;BIBLamdouar21&quot;).style.display=&quot;none&quot;;">
                           Bibtex </a> | <a
                           onclick="if (document.getElementById(&quot;ABSLamdouar21&quot;).style.display==&quot;none&quot;) document.getElementById(&quot;ABSLamdouar21&quot;).style.display=&quot;block&quot;; else document.getElementById(&quot;ABSLamdouar21&quot;).style.display=&quot;none&quot;;">
       		    Abstract </a> | <a href="https://www.robots.ox.ac.uk/~vgg/research/simo/"> Project Page </a> | <a href="https://www.robots.ox.ac.uk/~vgg/publications/2021/Lamdouar21/lamdouar21.pdf"> PDF </a></div>
                   <div style="display: none;" class="BibtexExpand" id="BIBLamdouar21">
                      <pre class="bibtex" style="text-align:left;">
@InProceedings{Lamdouar21,
    author       = "Hala Lamdouar and Weidi Xie and Andrew Zisserman",
    title        = "Segmenting Invisible Moving Objects",
    booktitle    = "British Machine Vision Conference",
    year         = "2021",
                }
                   </pre>
                   </div>
                   <div style="display: none; text-align:left;" class="AbstractExpand" id="ABSLamdouar21"><br>
                       Biological visual systems are exceptionally good at perceiving objects that undergo changes 
                       in appearance, pose, and position. In this paper, we aim to train a computational model with 
                       similar functionality to segment the moving objects in videos. We target the challenging cases 
                       when objects are ``invisible'' in the RGB video sequence, for example, breaking camouflage, where 
                       visual appearance from a static scene can barely provide informative cues, or locating the objects 
                       as a whole even under partial occlusion. To this end, we make the following contributions: (i) In order 
                       to train a motion segmentation model, we propose a scalable pipeline for generating synthetic training 
                       data, significantly reducing the requirements for labour-intensive annotations; (ii) We introduce a 
                       dual-head architecture (hybrid of ConvNets and Transformer) that takes a sequence of optical flows 
                       as input, and learns to segment the moving objects even when they are partially occluded or stop 
                       moving at certain points in videos; (iii) We conduct thorough ablation studies to analyse the critical 
                       components in data simulation, and validate the necessity of Transformer layers for aggregating 
                       temporal information and for developing object permanence. When evaluating on the MoCA camouflage 
                       dataset, the model trained only on synthetic data demonstrates state-of-the-art segmentation 
                       performance, even outperforming strong supervised approaches. In addition, we also evaluate on 
                       the popular benchmarks DAVIS2016 and SegTrackv2, and show competitive performance despite only 
                       processing optical flow.<br><br>
                   </div>
 
            </td>
          </tr>



</table>
<br>
<div class="page__inner-wrap">  
        <table style="width:150%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size:14px"><tbody>
          <tr>
             <td style="padding:20px;width:25%;vertical-align:middle;border:0">
               <div class="one">
               <div class="two">
               <img src="../images/motion_group.png">
                </div>

            </td>
            <td style="width:75%;vertical-align:middle;border:0">
							<a href="https://charigyang.github.io/motiongroup/resources/motiongroup.pdf">
                <papertitle style="font-size:16px"><b>Self-supervised Video Object Segmentation by Motion Grouping</b></papertitle>
              </a>
              <br>
              <a style="text-decoration:none" href="https://charigyang.github.io">Charig Yang</a>,
              <strong>Hala Lamdouar</strong>,
              <a style="text-decoration:none" href="https://erikalu.com">Erika Lu</a>,
              <a style="text-decoration:none" href="https://weidixie.github.io/">Weidi Xie</a>,
              <a style="text-decoration:none" href="http://www.robots.ox.ac.uk/~az/">Andrew Zisserman</a>
              <br>
              Full: <em>ICCV</em>, 2021 
              <br>
              Short: CVPR Workshop on Robust Video Scene Understanding, 2021 
              <font color="red"><strong>(Best Paper Award)</strong></font>
              <br>
                   <div class="links">
                       <a onclick="if (document.getElementById(&quot;BIByang2021selfsupervised&quot;).style.display==&quot;none&quot;) document.getElementById(&quot;BIByang2021selfsupervised&quot;).style.display=&quot;block&quot;; else document.getElementById(&quot;BIByang2021selfsupervised&quot;).style.display=&quot;none&quot;;">
                           Bibtex </a> | <a
                           onclick="if (document.getElementById(&quot;ABSyang2021selfsupervised&quot;).style.display==&quot;none&quot;) document.getElementById(&quot;ABSyang2021selfsupervised&quot;).style.display=&quot;block&quot;; else document.getElementById(&quot;ABSyang2021selfsupervised&quot;).style.display=&quot;none&quot;;">
       		    Abstract </a> | <a href="https://charigyang.github.io/motiongroup/"> Project Page </a> | <a href="https://charigyang.github.io/motiongroup/resources/motiongroup.pdf"> PDF </a> | <a href="https://arxiv.org/abs/2104.07658.pdf"> arXiv </a></div>
                   <div style="display: none;" class="BibtexExpand" id="BIByang2021selfsupervised">
                      <pre class="bibtex" style="text-align:left;">
@InProceedings{yang2021selfsupervised,
  title={Self-supervised Video Object Segmentation by Motion Grouping}, 
  author={Charig Yang and Hala Lamdouar and Erika Lu and Andrew Zisserman and Weidi Xie},
  booktitle={ICCV},
  year={2021},
}
                   </pre>
                   </div>
                   <div style="display: none; text-align:left;" class="AbstractExpand" id="ABSyang2021selfsupervised"><br>
                       Animals have evolved highly functional visual systems to understand motion, assisting perception even under 
                       complex environments. In this paper, we work towards developing a computer vision system able to segment
                        objects by exploiting motion cues, i.e. motion segmentation. We make the following contributions: First, 
                        we introduce a simple variant of the Transformer to segment optical flow frames into primary objects 
                        and the background. Second, we train the architecture in a self-supervised manner, i.e. without using 
                        any manual annotations. Third, we analyze several critical components of our method and conduct thorough 
                        ablation studies to validate their necessity. Fourth, we evaluate the proposed architecture on public benchmarks 
                        (DAVIS2016, SegTrackv2, and FBMS59). Despite using only optical flow as input, our approach achieves superior results 
                        compared to previous state-of-the-art self-supervised methods, while being an order of magnitude faster. 
                        We additionally evaluate on a challenging camouflage dataset (MoCA), significantly outperforming the other self-supervised 
                        approaches, and comparing favourably to the top supervised approach, highlighting the importance of motion cues, and the 
                        potential bias towards visual appearance in existing video segmentation models.<br><br>
                   </div>
 
            </td>
          </tr>



</table>            

<br>
     
<div class="page__inner-wrap">  
        <table style="width:150%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;font-size:14px"><tbody>
          <tr>
             <td style="padding:20px;width:25%;vertical-align:middle;border:0">
               <div class="one">
               <div class="two">
               <img src="../images/moca.png">
                </div>

            </td>
            <td style="width:75%;vertical-align:middle;border:0">
							<a href="http://www.robots.ox.ac.uk/~vgg/publications/2020/Lamdouar20/lamdouar20.pdf">
                <papertitle style="font-size:16px"><b>Betrayed by Motion: Camouflaged Object Discovery via Motion Segmentation</b></papertitle>
              </a>
              <br>
              <strong>Hala Lamdouar</strong>,
              <a style="text-decoration:none" href="https://charigyang.github.io">Charig Yang</a>, 
              <a style="text-decoration:none" href="https://weidixie.github.io/">Weidi Xie</a>,
              <a style="text-decoration:none" href="http://www.robots.ox.ac.uk/~az/">Andrew Zisserman</a>
              <br>
              <em>ACCV</em>, 2020 
              <br>
                   <div class="links">
                       <a onclick="if (document.getElementById(&quot;BIBLamdouar20&quot;).style.display==&quot;none&quot;) document.getElementById(&quot;BIBLamdouar20&quot;).style.display=&quot;block&quot;; else document.getElementById(&quot;BIBLamdouar20&quot;).style.display=&quot;none&quot;;">
                           Bibtex </a> | <a
                           onclick="if (document.getElementById(&quot;ABSLamdouar20&quot;).style.display==&quot;none&quot;) document.getElementById(&quot;ABSLamdouar20&quot;).style.display=&quot;block&quot;; else document.getElementById(&quot;ABSLamdouar20&quot;).style.display=&quot;none&quot;;">
       		    Abstract </a> | <a href="https://www.robots.ox.ac.uk/~vgg/data/MoCA/"> Project Page </a> | <a href="http://www.robots.ox.ac.uk/~vgg/publications/2020/Lamdouar20/lamdouar20.pdf"> PDF </a> | <a href="https://arxiv.org/abs/2011.11630"> arXiv </a></div>
                   <div style="display: none;" class="BibtexExpand" id="BIBLamdouar20">
                      <pre class="bibtex" style="text-align:left;">
@Article{Lamdouar20,
author       = "Hala Lamdouar and Charig Yang and Weidi Xie and Andrew Zisserman",
title        = "Betrayed by Motion: Camouflaged Object Discovery via Motion Segmentation",
journal      = "Asian Conference on Computer Vision",
year         = "2020",
}
                   </pre>
                   </div>
                   <div style="display: none; text-align:left;" class="AbstractExpand" id="ABSLamdouar20"><br>
                       The objective of this paper is to design a computational architecture that discovers camouflaged objects
                       in videos, specifically by exploiting motion information to perform object segmentation. We make the
                       following three contributions: (i) We propose a novel architecture that consists of two essential
                       components for breaking camouflage, namely, a differentiable registration module to align consecutive
                       frames based on the background, which effectively emphasises the object boundary in the difference
                       image, and a motion segmentation module with memory that discovers the moving objects, while maintaining
                       the object permanence even when motion is absent at some point. (ii) We collect the first large-scale
                       Moving Camouflaged Animals (MoCA) video dataset, which consists of over 140 clips across a diverse range
                       of animals (67 categories). (iii) We demonstrate the effectiveness of the proposed model on MoCA, and
                       achieve competitive performance on the unsupervised segmentation protocol on DAVIS2016 by only relying
                       on motion.<br><br>
                   </div>
 
            </td>
          </tr>



</table>            

</pre></div></div>



      <footer class="page__meta">
        
        




      </footer>

      

    </div>

    
  </article>

  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
    
    <li><a href="https://hlamdouar.github.io/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Hala Lamdouar. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="https://hlamdouar.github.io/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

